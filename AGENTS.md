# DKL Tabular Regression Project with Categorical Handling

## ğŸ’¾ í™˜ê²½ ì„¤ì •

Please generate a Python 3.10+ compatible script that installs the following packages (with compatible versions for CUDA 11.8):

```bash
pip install torch==1.13.1+cu118 torchvision==0.14.1+cu118 torchaudio==0.13.1+cu118 -f https://download.pytorch.org/whl/torch_stable.html
pip install gpytorch==1.10.0
pip install scikit-learn pandas matplotlib seaborn
```

---

## âœ… ë°ì´í„°ì…‹ ì²˜ë¦¬ ìš”êµ¬ì‚¬í•­

Please create a flexible preprocessor that accepts a Pandas `DataFrame` and does the following:

1. Accepts arguments:
   - `x_columns`: list of feature column names
   - `target_column`: name of regression target column
2. Identifies which of the `x_columns` are categorical (`dtype == 'object' or 'category'`)
3. Performs:
   - **One-hot encoding** for categorical features (using `pd.get_dummies`)
   - **StandardScaler** for numeric features and target
4. Automatically splits the dataset into:
   - 70% train
   - 15% validation
   - 15% test
5. Returns:
   - `X_train, y_train, X_val, y_val, X_test, y_test` (as torch.Tensor)

Save this logic in `data/preprocess.py`

---

## ğŸ“ ì „ì²´ í”„ë¡œì íŠ¸ êµ¬ì„±

Generate code for the following structure:

```
dkl_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ preprocess.py        # Categorical + numerical preprocessing
â”‚   â””â”€â”€ example_dataset.csv  # Sample dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ dkl_model.py
â”‚   â”œâ”€â”€ ensemble_dkl.py
â”‚   â””â”€â”€ quantile_dkl.py
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_base.py
â”‚   â”œâ”€â”€ train_ensemble.py
â”‚   â””â”€â”€ train_quantile.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ loss.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ plot.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ results/
â”œâ”€â”€ main.py
â””â”€â”€ requirements.txt
```

---

## ğŸ§  ëª¨ë¸ ìš”êµ¬ì‚¬í•­

Implement the following models in PyTorch + GPyTorch:

1. **Base DKL Model**
   - MLP feature extractor
   - GP Layer with 128 inducing points, RBF kernel

2. **Ensemble DKL**
   - 5 independent Base DKL models
   - Aggregate mean and total Ïƒ (epistemic + aleatoric)

3. **Quantile Hybrid DKL**
   - Head for 10%, 50%, 90% quantile prediction
   - Loss includes pinball loss for quantiles

All models must support `.to(device)` and fallback to CPU if CUDA is unavailable.

---

## ğŸ“‰ í•™ìŠµ ìš”êµ¬ì‚¬í•­

Each of the 3 training scripts must:

- Accept file path to CSV and `x_columns`, `target_column`
- Run preprocessing using `data/preprocess.py`
- Train for max 100 epochs, with early stopping (patience=10)
- Use CosineAnnealingLR scheduler
- Save best model to `checkpoints/`
- Save predictions and plots to `results/`

Each script must save:

- MAE, RMSE, sigma-MAE correlation
- Coverage (% within 95% CI)
- Ïƒ vs MAE scatter plot
- Prediction vs True plot
- Quantile Interval plot (quantile model only)

---

## ğŸ“¦ ì‹¤í–‰ ëª…ë ¹ì–´ ì˜ˆì‹œ

Each script must be runnable standalone via CLI:

```bash
python train/train_base.py \
  --csv_path data/example_dataset.csv \
  --x_columns "feature1,feature2,cat_feature1,cat_feature2" \
  --target_column "target"

python train/train_ensemble.py ...  # ë™ì¼í•˜ê²Œ ë™ì‘

python train/train_quantile.py ...  # ë™ì¼í•˜ê²Œ ë™ì‘
```

Use `argparse` to receive arguments.

---

## ğŸ§¾ requirements.txt

Please generate a requirements.txt with all versions explicitly pinned for full reproducibility.

---

## ğŸ“˜ ì°¸ê³  ë°ì´í„°

If `data/example_dataset.csv` does not exist, synthesize a mixed-type dataset using `sklearn.datasets.make_regression` and append categorical columns using:

```python
import numpy as np
import pandas as pd
from sklearn.datasets import make_regression

X, y = make_regression(n_samples=2000, n_features=5, noise=0.1, random_state=42)
df = pd.DataFrame(X, columns=[f'num_{i}' for i in range(5)])
df['cat_feature1'] = np.random.choice(['A', 'B', 'C'], size=2000)
df['cat_feature2'] = np.random.choice(['X', 'Y'], size=2000)
df['target'] = y
df.to_csv('data/example_dataset.csv', index=False)
```

---

## ğŸ“¦ ì‚°ì¶œë¬¼

- Save Python scripts in respective folders above
- Output results in `/results/` with timestamps or model names
- Save best models in `/checkpoints/`
